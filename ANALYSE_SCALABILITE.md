# ğŸ” Analyse de ScalabilitÃ© et Robustesse - FakeTect

**Date d'analyse** : 7 janvier 2026  
**Objectif** : Ã‰valuer la capacitÃ© du systÃ¨me Ã  gÃ©rer plusieurs clients et analyses simultanÃ©es

---

## ğŸ“Š RÃ‰SUMÃ‰ EXÃ‰CUTIF

### âœ… Points forts actuels
- Rate limiting multi-niveaux implÃ©mentÃ©
- Cache Redis pour optimiser les analyses identiques
- Gestion d'erreurs robuste avec fallback gracieux
- Prisma ORM avec connection pooling natif
- Health checks pour monitoring
- Logging structurÃ© (Winston)

### âš ï¸ Points faibles critiques
- **Pas de clustering Node.js** â†’ 1 seul CPU utilisÃ©
- **Uploads synchrones** â†’ Bloquage lors de gros fichiers
- **Analyses sÃ©quentielles** â†’ Pas de queue pour gÃ©rer la charge
- **Connection pool non configurÃ©** â†’ Risque d'Ã©puisement
- **Pas de scaling horizontal** â†’ LimitÃ© Ã  1 instance
- **Uploads stockÃ©s en local** â†’ ProblÃ¨me en multi-instance

---

## ğŸ”´ PROBLÃˆMES CRITIQUES

### 1. **Mono-processus (1 seul CPU utilisÃ©)**

**ProblÃ¨me** :
```javascript
// backend/src/index.js
app.listen(PORT, async () => {
  // 1 seul worker = 1 seul CPU
});
```

**Impact** :
- Sur un serveur 8 cores, seulement 12.5% de CPU utilisÃ©
- Si une requÃªte bloque (analyse longue), toutes les autres attendent
- Pas de haute disponibilitÃ© : si le process crash, tout s'arrÃªte

**Solution recommandÃ©e** :
```javascript
const cluster = require('cluster');
const os = require('os');

if (cluster.isMaster) {
  const numWorkers = os.cpus().length; // Utiliser tous les CPUs
  
  console.log(`ğŸš€ Master process ${process.pid} - Starting ${numWorkers} workers`);
  
  for (let i = 0; i < numWorkers; i++) {
    cluster.fork();
  }
  
  cluster.on('exit', (worker, code, signal) => {
    console.log(`âš ï¸ Worker ${worker.process.pid} died. Starting a new one...`);
    cluster.fork(); // Auto-restart
  });
} else {
  // Code actuel de l'app
  app.listen(PORT, () => {
    console.log(`Worker ${process.pid} started on port ${PORT}`);
  });
}
```

---

### 2. **Analyses synchrones bloquantes**

**ProblÃ¨me actuel** :
```javascript
// backend/src/routes/analysis.js ligne 76
const fileStream = fs.createReadStream(req.file.path);
result = await detection.analyze(fileStream, req.file.mimetype, req.file.originalname);
// âš ï¸ Si l'analyse prend 30 secondes, le worker est bloquÃ©
```

**Impact** :
- Pendant qu'un utilisateur attend son analyse (15-30s pour vidÃ©o), personne d'autre ne peut Ãªtre servi par ce worker
- Avec 100 utilisateurs simultanÃ©s â†’ file d'attente massive

**Solution recommandÃ©e** : **Queue systÃ¨me (Bull/BullMQ)**

```javascript
// backend/src/services/analysisQueue.js
const Queue = require('bull');

const analysisQueue = new Queue('video-analysis', {
  redis: {
    host: process.env.REDIS_HOST,
    port: process.env.REDIS_PORT,
    password: process.env.REDIS_PASSWORD
  }
});

// Worker de traitement (peut Ãªtre sÃ©parÃ©)
analysisQueue.process(10, async (job) => { // 10 jobs parallÃ¨les max
  const { filePath, mimeType, userId } = job.data;
  
  const result = await detection.analyze(filePath, mimeType);
  
  // Sauvegarder en BDD
  await prisma.analysis.update({
    where: { id: job.data.analysisId },
    data: { result: JSON.stringify(result), status: 'COMPLETED' }
  });
  
  return result;
});

// Route API
router.post('/file', auth, checkLimit, upload.single('file'), async (req, res) => {
  // CrÃ©er l'analyse en BDD avec status PENDING
  const analysis = await prisma.analysis.create({
    data: { 
      userId: req.user.id, 
      status: 'PENDING',
      fileName: req.file.originalname 
    }
  });
  
  // Ajouter Ã  la queue (non-bloquant)
  await analysisQueue.add({
    analysisId: analysis.id,
    filePath: req.file.path,
    mimeType: req.file.mimetype,
    userId: req.user.id
  }, {
    attempts: 3, // 3 tentatives
    backoff: { type: 'exponential', delay: 5000 }
  });
  
  // RÃ©ponse immÃ©diate (WebSocket pour notifier quand fini)
  res.json({ 
    analysisId: analysis.id, 
    status: 'PENDING',
    message: 'Analyse en cours, vous serez notifiÃ©' 
  });
});
```

---

### 3. **Connection Pool Prisma non configurÃ©**

**ProblÃ¨me actuel** :
```javascript
// backend/src/config/db.js
const prisma = new PrismaClient(); // Pas de config de pool !
```

**Impact** :
- Neon PostgreSQL limite Ã  **~100 connexions simultanÃ©es**
- Sans pool configurÃ©, risque d'Ã©puisement lors de pics de trafic
- Erreur : "too many connections" â†’ app crash

**Solution** :
```javascript
const prisma = new PrismaClient({
  datasources: {
    db: {
      url: process.env.DATABASE_URL,
    },
  },
  log: ['error', 'warn'],
  // Configuration du pool
  connection_limit: 20, // Max 20 connexions par worker
  pool_timeout: 10, // Timeout aprÃ¨s 10s
});

// Alternative avec pooling Neon
// DATABASE_URL="postgresql://user:pass@host/db?connection_limit=20&pool_timeout=10"
```

**Calcul recommandÃ©** :
- Si 4 workers Node.js Ã— 20 connexions = 80 connexions max
- Laisse 20 connexions pour admin/maintenance
- Total < 100 (limite Neon Free)

---

### 4. **Uploads en local (non scalable)**

**ProblÃ¨me** :
```javascript
// backend/src/routes/analysis.js ligne 17-23
const storage = multer.diskStorage({
  destination: (req, file, cb) => {
    const dir = path.join(__dirname, '../../uploads'); // âš ï¸ Stockage LOCAL
    cb(null, dir);
  }
});
```

**Impact** :
- Si vous dÃ©ployez 3 instances sur Render â†’ chaque instance a ses propres fichiers
- Utilisateur upload sur instance A, mais demande le fichier depuis instance B â†’ 404 NOT FOUND
- Pas de persistence : Render redÃ©marre = fichiers perdus

**Solution** : **S3-compatible storage (AWS S3, Cloudflare R2, Backblaze B2)**

```javascript
// backend/src/config/s3.js
const { S3Client, PutObjectCommand } = require('@aws-sdk/client-s3');

const s3 = new S3Client({
  region: process.env.AWS_REGION || 'auto',
  endpoint: process.env.S3_ENDPOINT, // Cloudflare R2
  credentials: {
    accessKeyId: process.env.S3_ACCESS_KEY,
    secretAccessKey: process.env.S3_SECRET_KEY,
  },
});

async function uploadToS3(file) {
  const key = `uploads/${Date.now()}-${file.originalname}`;
  
  await s3.send(new PutObjectCommand({
    Bucket: process.env.S3_BUCKET,
    Key: key,
    Body: fs.createReadStream(file.path),
    ContentType: file.mimetype,
  }));
  
  return `https://${process.env.S3_BUCKET}.s3.amazonaws.com/${key}`;
}

// Route
router.post('/file', upload.single('file'), async (req, res) => {
  const fileUrl = await uploadToS3(req.file);
  // Supprimer le fichier local
  fs.unlinkSync(req.file.path);
  
  await prisma.analysis.create({
    data: { fileUrl } // URL S3 accessible partout
  });
});
```

**Alternatives Ã©conomiques** :
- **Cloudflare R2** : 10GB gratuit/mois, 0$ egress
- **Backblaze B2** : 10GB gratuit/mois
- **Supabase Storage** : 1GB gratuit

---

### 5. **Rate limiting basÃ© sur IP (contournable)**

**ProblÃ¨me actuel** :
```javascript
// backend/src/middleware/rateLimiter.js ligne 11-24
const globalLimiter = rateLimit({
  windowMs: 15 * 60 * 1000,
  max: 200, // Par IP
});
```

**VulnÃ©rabilitÃ©** :
- Utilisateur malveillant peut changer d'IP (VPN, proxy, mobile data)
- DerriÃ¨re un proxy/CDN, toutes les requÃªtes ont la mÃªme IP

**Solution** : **Rate limiting par userId + IP**

```javascript
const createSmartLimiter = (options) => {
  return rateLimit({
    ...options,
    keyGenerator: (req) => {
      // Si authentifiÃ© : limit par userId
      if (req.user?.id) {
        return `user:${req.user.id}`;
      }
      // Sinon : IP + User-Agent (plus difficile Ã  contourner)
      return `ip:${req.ip}:${req.get('user-agent')}`;
    }
  });
};

const analysisLimiter = createSmartLimiter({
  windowMs: 60 * 1000,
  max: async (req) => {
    // Limite dynamique selon le plan
    if (req.user?.plan === 'PRO') return 100;
    if (req.user?.plan === 'PREMIUM') return 500;
    return 10; // FREE
  }
});
```

---

### 6. **Pas de timeout sur les analyses API**

**ProblÃ¨me** :
```javascript
// backend/src/services/detection.js ligne 10
return await this.analyzeVideoWithSightengine(input, mimeType, filename);
// âš ï¸ Pas de timeout ! Peut bloquer indÃ©finiment
```

**Impact** :
- Si Sightengine ne rÃ©pond jamais â†’ le worker reste bloquÃ© Ã  vie
- Accumulation de workers morts â†’ serveur inutilisable

**Solution** :
```javascript
async analyzeWithTimeout(input, mimeType, filename, timeoutMs = 60000) {
  return Promise.race([
    this.analyzeVideoWithSightengine(input, mimeType, filename),
    new Promise((_, reject) => 
      setTimeout(() => reject(new Error('Analysis timeout')), timeoutMs)
    )
  ]);
}
```

---

## ğŸŸ¡ PROBLÃˆMES MOYENS

### 7. **Multer limite taille mais pas nombre de requÃªtes**

**ProblÃ¨me** :
```javascript
limits: { fileSize: 100 * 1024 * 1024 }, // 100MB
```

- Utilisateur malveillant peut upload 100 fichiers de 100MB en 1 minute
- 10GB de uploads = serveur saturÃ©

**Solution** :
```javascript
const uploadLimiter = rateLimit({
  windowMs: 60 * 1000,
  max: 5, // Max 5 uploads/minute
  skipSuccessfulRequests: false
});

router.post('/file', uploadLimiter, auth, upload.single('file'), ...);
```

---

### 8. **Logs non structurÃ©s pour monitoring**

**AmÃ©lioration** :
```javascript
// Ajouter des mÃ©triques Prometheus
const promClient = require('prom-client');

const analysisCounter = new promClient.Counter({
  name: 'faketect_analyses_total',
  help: 'Total analyses performed',
  labelNames: ['type', 'status', 'plan']
});

const analysisDuration = new promClient.Histogram({
  name: 'faketect_analysis_duration_seconds',
  help: 'Analysis duration',
  labelNames: ['type', 'provider']
});

// Dans la route
const timer = analysisDuration.startTimer({ type, provider });
// ... analyse ...
timer();
analysisCounter.inc({ type, status: 'success', plan: req.user.plan });
```

---

## ğŸ“ˆ ARCHITECTURE RECOMMANDÃ‰E POUR SCALABILITÃ‰

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Cloudflare    â”‚ â† CDN + DDoS protection
â”‚   (ou Vercel)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Load Balancer â”‚ â† Nginx / Render Load Balancer
â”‚   (Round Robin) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         â”‚         â”‚         â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”
â”‚ API 1 â”‚ â”‚ API 2â”‚ â”‚ API 3 â”‚ â”‚ API 4 â”‚ â† 4 instances Node.js
â”‚4 CPUs â”‚ â”‚4 CPUsâ”‚ â”‚4 CPUs â”‚ â”‚4 CPUs â”‚   (cluster interne)
â””â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”˜
    â”‚        â”‚         â”‚         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Redis Cluster  â”‚ â† Cache + Queue (Bull)
    â”‚   (Upstash)     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ PostgreSQL Pool â”‚ â† Neon (connection pooling)
    â”‚  (Neon/Supabase)â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  S3 Storage     â”‚ â† Cloudflare R2 / AWS S3
    â”‚ (uploads/media) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ PLAN D'ACTION PRIORITAIRE

### Phase 1 : StabilitÃ© (1-2 jours) âš¡ CRITIQUE

1. **Ajouter clustering Node.js**
   - Fichier : `backend/src/cluster.js`
   - Utiliser tous les CPUs disponibles
   - Auto-restart sur crash

2. **Configurer Prisma connection pool**
   - Limiter Ã  20 connexions/worker
   - Ã‰viter Ã©puisement DB

3. **Ajouter timeouts sur analyses API**
   - Max 60s pour vidÃ©os, 30s pour images
   - Ã‰viter workers bloquÃ©s indÃ©finiment

### Phase 2 : ScalabilitÃ© (3-5 jours) ğŸ”¥ IMPORTANT

4. **ImplÃ©menter queue systÃ¨me (Bull)**
   - Analyses asynchrones
   - Gestion de la charge
   - Retry automatique

5. **Migrer uploads vers S3**
   - Cloudflare R2 ou AWS S3
   - Persistence garantie
   - Multi-instance compatible

6. **Rate limiting intelligent**
   - Par userId + IP
   - Limites dynamiques selon plan
   - MÃ©triques dÃ©taillÃ©es

### Phase 3 : Monitoring (2-3 jours) ğŸ“Š RECOMMANDÃ‰

7. **Ajouter Prometheus + Grafana**
   - MÃ©triques temps rÃ©el
   - Alertes automatiques
   - Dashboards de performance

8. **APM (Application Performance Monitoring)**
   - Sentry pour erreurs
   - New Relic / Datadog pour performance
   - Alertes sur mÃ©triques critiques

### Phase 4 : Optimisation (optionnel) âœ¨

9. **CDN pour assets statiques**
10. **Database read replicas** (Neon Pro)
11. **Edge caching** (Cloudflare Workers)

---

## ğŸ“Š CAPACITÃ‰ ACTUELLE vs RECOMMANDÃ‰E

### Configuration actuelle
- **Instances** : 1
- **CPUs utilisÃ©s** : 1/4 (25%)
- **Analyses simultanÃ©es** : 1-2
- **Utilisateurs simultanÃ©s** : ~10-20
- **Uploads** : Stockage local (volatil)
- **Rate limits** : Par IP (contournable)

### AprÃ¨s amÃ©liorations
- **Instances** : 4+ (horizontal scaling)
- **CPUs utilisÃ©s** : 100% (cluster mode)
- **Analyses simultanÃ©es** : 50-100 (queue)
- **Utilisateurs simultanÃ©s** : 500-1000
- **Uploads** : S3 (persistant + CDN)
- **Rate limits** : Par userId (strict)

---

## ğŸ’° ESTIMATION COÃ›TS

### Gratuit / Low-cost
- **Redis** : Upstash (10K requÃªtes/jour gratuit)
- **S3** : Cloudflare R2 (10GB gratuit)
- **DB** : Neon Free (0.5GB, suffisant pour dÃ©marrer)
- **Hosting** : Render Free (limitÃ© mais fonctionne)

### Production recommandÃ©e (~50-100$/mois)
- **Redis** : Upstash Pro (~10$/mois)
- **S3** : Cloudflare R2 (~5$/mois pour 50GB)
- **DB** : Neon Scale (~25$/mois, connection pooling)
- **Hosting** : Render Pro (~25$/mois, 2GB RAM)
- **Monitoring** : Sentry Free + Prometheus self-hosted

---

## ğŸ¯ RECOMMANDATION FINALE

**Votre code est fonctionnel pour 10-20 utilisateurs simultanÃ©s, mais PAS SCALABLE pour une vraie charge.**

### Actions immÃ©diates (ce week-end) :
1. âœ… **Clustering Node.js** (2h de dev)
2. âœ… **Prisma connection pool** (30 min)
3. âœ… **Timeouts API** (1h)

### Actions court-terme (semaine prochaine) :
4. ğŸ”„ **Bull Queue** (1 jour de dev)
5. ğŸ“¦ **Migration S3** (1 jour de dev)

### Actions moyen-terme (ce mois) :
6. ğŸ“Š **Monitoring Prometheus** (2 jours)
7. ğŸ” **Rate limiting avancÃ©** (1 jour)

**Avec ces amÃ©liorations, vous pourrez gÃ©rer 500-1000 utilisateurs simultanÃ©s facilement.**

---

## ğŸ“ CHECKLIST DÃ‰PLOIEMENT PRODUCTION

- [ ] Clustering activÃ© (4+ workers)
- [ ] Connection pool configurÃ© (max 20/worker)
- [ ] Queue Bull/BullMQ opÃ©rationnelle
- [ ] Uploads sur S3/R2 (pas en local)
- [ ] Timeouts API (30-60s)
- [ ] Rate limiting par userId
- [ ] Monitoring Sentry activÃ©
- [ ] Logs centralisÃ©s (Winston â†’ Cloudwatch)
- [ ] Health checks configurÃ©s
- [ ] Auto-scaling activÃ© (Render/AWS)
- [ ] Backups DB quotidiens
- [ ] CDN configurÃ© (Cloudflare)

